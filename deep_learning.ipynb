{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постройте модель для классификации FashionMNIST. Попробуйте получить качество на тестовой выборке не ниже 88%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision as tv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tv.datasets.FashionMNIST('.', train=True, transform=tv.transforms.ToTensor(), download=True)\n",
    "test_dataset = tv.datasets.FashionMNIST('.', train=False, transform=tv.transforms.ToTensor(), download=True)\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE)\n",
    "test = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x185461ca220>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_dataset[0][0].numpy().reshape(28,28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 384),\n",
    "    torch.nn.BatchNorm1d(384),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(384),\n",
    "    torch.nn.Linear(384, 256),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(256),\n",
    "    torch.nn.Linear(256, 10),\n",
    "    torch.nn.LogSoftmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model.parameters(), eps=1e-08, lr=0.001)\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, train_loss: 0.4289362969550681, train_acc: 0.8457, test_loss: 0.38210840076208114, test_acc: 0.8644\n",
      "ep: 1, train_loss: 0.3162091678761421, train_acc: 0.8832833333333333, test_loss: 0.35354749448597433, test_acc: 0.8746\n",
      "ep: 2, train_loss: 0.2748858131626819, train_acc: 0.8990833333333333, test_loss: 0.3438053146004677, test_acc: 0.8755\n",
      "ep: 3, train_loss: 0.2451611061679556, train_acc: 0.9097333333333333, test_loss: 0.34612213633954525, test_acc: 0.8768\n",
      "ep: 4, train_loss: 0.2213530848635004, train_acc: 0.9189333333333334, test_loss: 0.3438006989657879, test_acc: 0.8799\n",
      "ep: 5, train_loss: 0.20120657473168474, train_acc: 0.9255, test_loss: 0.3391278598457575, test_acc: 0.8857\n",
      "ep: 6, train_loss: 0.18107448743378862, train_acc: 0.9334333333333333, test_loss: 0.34218670763075354, test_acc: 0.887\n",
      "ep: 7, train_loss: 0.16388326265076372, train_acc: 0.94065, test_loss: 0.35062150517478585, test_acc: 0.8864\n",
      "ep: 8, train_loss: 0.15129439684938878, train_acc: 0.9449333333333333, test_loss: 0.36285193599760535, test_acc: 0.8855\n",
      "ep: 9, train_loss: 0.1352197711455061, train_acc: 0.9507666666666666, test_loss: 0.3802383481990546, test_acc: 0.8856\n",
      "ep: 10, train_loss: 0.12421384322199415, train_acc: 0.95475, test_loss: 0.3905664168763906, test_acc: 0.8833\n",
      "ep: 11, train_loss: 0.1146734115766718, train_acc: 0.9581333333333333, test_loss: 0.4313827143982053, test_acc: 0.8816\n",
      "ep: 12, train_loss: 0.10650097084172229, train_acc: 0.9603, test_loss: 0.45719445273280146, test_acc: 0.8775\n",
      "ep: 13, train_loss: 0.10000829216330609, train_acc: 0.9641666666666666, test_loss: 0.45877684876322744, test_acc: 0.8775\n",
      "ep: 14, train_loss: 0.09327919976983932, train_acc: 0.9663333333333334, test_loss: 0.45036374442279337, test_acc: 0.8851\n",
      "ep: 15, train_loss: 0.08853848475883616, train_acc: 0.9673, test_loss: 0.4496115319430828, test_acc: 0.8828\n",
      "ep: 16, train_loss: 0.08033175641234885, train_acc: 0.9707833333333333, test_loss: 0.4541581048164517, test_acc: 0.8861\n",
      "ep: 17, train_loss: 0.07232848073732345, train_acc: 0.97365, test_loss: 0.4722620718181133, test_acc: 0.8885\n",
      "ep: 18, train_loss: 0.07016307092568976, train_acc: 0.97415, test_loss: 0.4932796563953161, test_acc: 0.889\n",
      "ep: 19, train_loss: 0.06505364643290956, train_acc: 0.9759666666666666, test_loss: 0.49698630422353746, test_acc: 0.8887\n"
     ]
    }
   ],
   "source": [
    "for ep in range(num_epochs):\n",
    "    train_iters, train_passed  = 0, 0\n",
    "    train_loss, train_acc = 0., 0.\n",
    "    \n",
    "    for X, y in train:\n",
    "        \n",
    "        trainer.zero_grad()\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred, y)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "        train_loss += l.item()\n",
    "        train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        train_iters += 1\n",
    "        train_passed += len(X)\n",
    "    \n",
    "    test_iters, test_passed  = 0, 0\n",
    "    test_loss, test_acc = 0., 0.\n",
    "    for X, y in test:\n",
    "        y_pred = model(X)\n",
    "        l = loss(y_pred, y)\n",
    "        test_loss += l.item()\n",
    "        test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        test_iters += 1\n",
    "        test_passed += len(X)\n",
    "        \n",
    "    print(\"ep: {}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "        ep, train_loss / train_iters, train_acc / train_passed,\n",
    "        test_loss / test_iters, test_acc / test_passed)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "эксперименты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(784, 1568),\n",
    "    torch.nn.BatchNorm1d(1568),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(1568),\n",
    "    torch.nn.Linear(1568, 512),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.BatchNorm1d(512),\n",
    "    torch.nn.Linear(512, 10),\n",
    "    torch.nn.LogSoftmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "trainer = torch.optim.Adam(model_2.parameters(), eps=1e-08, lr=0.001)\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ep: 0, train_loss: 0.4233456721965303, train_acc: 0.8448666666666667, test_loss: 0.3789800897240639, test_acc: 0.8642\n",
      "ep: 1, train_loss: 0.31592407328017214, train_acc: 0.8827166666666667, test_loss: 0.3598223298788071, test_acc: 0.8719\n",
      "ep: 2, train_loss: 0.2733970519076002, train_acc: 0.8982833333333333, test_loss: 0.3551431104540825, test_acc: 0.8735\n",
      "ep: 3, train_loss: 0.24177077786719545, train_acc: 0.9101333333333333, test_loss: 0.3597717955708504, test_acc: 0.8753\n",
      "ep: 4, train_loss: 0.21676141068022303, train_acc: 0.9196166666666666, test_loss: 0.36301939003169537, test_acc: 0.8782\n",
      "ep: 5, train_loss: 0.19387590295456825, train_acc: 0.9290666666666667, test_loss: 0.35957758538424966, test_acc: 0.8819\n",
      "ep: 6, train_loss: 0.1770830457514905, train_acc: 0.9342, test_loss: 0.36902467869222166, test_acc: 0.8816\n",
      "ep: 7, train_loss: 0.16598668535973163, train_acc: 0.9392666666666667, test_loss: 0.378790102340281, test_acc: 0.8808\n",
      "ep: 8, train_loss: 0.14725501083947243, train_acc: 0.9464, test_loss: 0.41184566244482995, test_acc: 0.879\n",
      "ep: 9, train_loss: 0.1337913782831202, train_acc: 0.9501833333333334, test_loss: 0.4056435340084136, test_acc: 0.88\n",
      "ep: 10, train_loss: 0.12145102987898157, train_acc: 0.9552666666666667, test_loss: 0.41436013486236334, test_acc: 0.8828\n",
      "ep: 11, train_loss: 0.11182990126470302, train_acc: 0.95855, test_loss: 0.41368323639035226, test_acc: 0.8852\n",
      "ep: 12, train_loss: 0.10418545427791616, train_acc: 0.9613333333333334, test_loss: 0.45141981085762384, test_acc: 0.8799\n",
      "ep: 13, train_loss: 0.09363209664663102, train_acc: 0.9651666666666666, test_loss: 0.4492038953001611, test_acc: 0.8858\n",
      "ep: 14, train_loss: 0.08482116353004537, train_acc: 0.9682666666666667, test_loss: 0.4537087780190632, test_acc: 0.885\n",
      "ep: 15, train_loss: 0.08207030701351926, train_acc: 0.96895, test_loss: 0.492329392573447, test_acc: 0.8817\n",
      "ep: 16, train_loss: 0.07772227464679708, train_acc: 0.9702, test_loss: 0.4885660473722965, test_acc: 0.8856\n",
      "ep: 17, train_loss: 0.07245075755772439, train_acc: 0.97295, test_loss: 0.49359194058924916, test_acc: 0.8866\n",
      "ep: 18, train_loss: 0.06727993471666853, train_acc: 0.97485, test_loss: 0.516786715015769, test_acc: 0.885\n",
      "ep: 19, train_loss: 0.06324424550254294, train_acc: 0.9767166666666667, test_loss: 0.5426732824416831, test_acc: 0.8855\n"
     ]
    }
   ],
   "source": [
    "for ep in range(num_epochs):\n",
    "    train_iters, train_passed  = 0, 0\n",
    "    train_loss, train_acc = 0., 0.\n",
    "    \n",
    "    for X, y in train:\n",
    "        \n",
    "        trainer.zero_grad()\n",
    "        y_pred = model_2(X)\n",
    "        l = loss(y_pred, y)\n",
    "        l.backward()\n",
    "        trainer.step()\n",
    "        train_loss += l.item()\n",
    "        train_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        train_iters += 1\n",
    "        train_passed += len(X)\n",
    "    \n",
    "    test_iters, test_passed  = 0, 0\n",
    "    test_loss, test_acc = 0., 0.\n",
    "    for X, y in test:\n",
    "        y_pred = model_2(X)\n",
    "        l = loss(y_pred, y)\n",
    "        test_loss += l.item()\n",
    "        test_acc += (y_pred.argmax(dim=1) == y).sum().item()\n",
    "        test_iters += 1\n",
    "        test_passed += len(X)\n",
    "        \n",
    "    print(\"ep: {}, train_loss: {}, train_acc: {}, test_loss: {}, test_acc: {}\".format(\n",
    "        ep, train_loss / train_iters, train_acc / train_passed,\n",
    "        test_loss / test_iters, test_acc / test_passed)\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
